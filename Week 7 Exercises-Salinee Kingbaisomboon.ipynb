{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Week 7 Exercises-Salinee Kingbaisomboon.ipynb","provenance":[{"file_id":"1fzRh0r_NtPoulqbdewmhrfyNDx5xWVBp","timestamp":1614185273877}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"db8puyKPtXRS"},"source":["# **RBOT 240 - Week 7 Exercises**\n","\n","Complete 3 of the following exercises."]},{"cell_type":"markdown","metadata":{"id":"HMC5M0nBPNZt"},"source":["---\r\n","\r\n","# <font color=\"blue\">My selected three questions are:</font>\r\n","<font color=\"blue\">- <b>Exercise PRML 9.14</b></font>\r\n","\r\n","<font color=\"blue\">- <b>Exercise D1</b></font>\r\n","\r\n","<font color=\"blue\">- <b>Exercise P1</b></font>\r\n","\r\n","---"]},{"cell_type":"markdown","metadata":{"id":"1g-bdOvRxKXV"},"source":["## Problem Exercises\n","\n","The problem exercises are based off the PRML suplemental reading.  You'll need to read the chapter 9 to do the exercises."]},{"cell_type":"markdown","metadata":{"id":"DezgXQ2nzLwl"},"source":["**(PRML 9.9)** Show that if we maximize (9.40) with respect to $\\Sigma_k$ and $\\pi_k$ while keeping the responsibilities $\\gamma(z_{nk})$ fixed, we obtain the closed form solutions given by (9.19) and (9.22)."]},{"cell_type":"markdown","metadata":{"id":"GKlo9Yn9CyFL"},"source":["**(PRML 9.11)** In Section 9.3.2, we obtained a relationship between K-means and EM for Gaussian mixtures by considering a mixture model in which all componenets have covariance $\\epsilon \\textbf{I}$.  Show that in the limit $\\epsilon \\rightarrow 0$, maximizing the expected complete data log likelihood for this model, given by (9.40), is equivalent to minimizing the distortion measure $J$ for the K-means algorithm given by (9.1)"]},{"cell_type":"markdown","metadata":{"id":"8WGuaV-lTZoo"},"source":["**<font color=\"blue\">(PRML 9.14)** Consider the joint distribution of latent and observed variables for the Bernoulli distribtuion obtained by forming the product of $p(\\textbf{x}|\\textbf{z},\\mu)$ given by (9.52) and $p(\\textbf{z}|\\pi)$ given by (9.53).  Show that if we marginalize this joint distibution with respect to x, then we obtain (9.47).</font>\r\n","\r\n","<font color=\"green\"><u><b>Answer</b></u></font>\r\n","\r\n","We're given below equation in the question (based on Bishop's textbook):\r\n","\r\n","$\r\n","\\begin{align}\r\n","\\mathbf{p(x|z,μ)} = \\prod_{k=1}^{K} p(X|\\mu_{k})^{z_{k}}\r\n","\\tag*{(9.52)}\r\n","\\end{align}\r\n","$\r\n","\r\n","$\r\n","\\begin{align}\r\n","\\mathbf{p(z|\\pi)} = \\prod_{k=1}^{K} \\pi{k}^{z_{k}}\r\n","\\tag*{(9.53)}\r\n","\\end{align}\r\n","$\r\n","\r\n","We need to show that if we marginalize this joint distibution with respect to x, we can obtain the following:\r\n","\r\n","$\r\n","\\begin{align}\r\n","\\mathbf{p(x|\\mu, \\pi)} = \\sum_{k=1}^{K} \\pi_{k}p(x|\\mu_{k})\r\n","\\tag*{(9.47)}\r\n","\\end{align}\r\n","$\r\n","\r\n","Let's perform the product of equations **(9.52)** and **(9.53)**:\r\n","\r\n","\\begin{equation}\r\n","\\begin{aligned}\r\n","\\mathbf{p(x, z|\\mu, \\pi)} &= p(x|z,\\mu) \\cdot p(z|\\pi) \\\\\r\n","  & = \\prod_{k=1}^{K} p(X|\\mu_{k})^{z_{k}} \\cdot \\prod_{k=1}^{K} \\pi{k}^{z_{k}} \\\\\r\n","  & = \\prod_{k=1}^{K} \\big[ \\pi_{k}p(x | \\mu_{k}) \\big]^{z{k}}\r\n","\\end{aligned}\r\n","\\end{equation}\r\n","\r\n","Then, we marginalized over $z$, result in:\r\n","\r\n","\\begin{equation}\r\n","\\begin{aligned}\r\n","\\mathbf{p(x|\\mu)} &= \\sum_{z} p(x, z|\\mu, \\pi)\\\\\r\n","& = \\sum_{k} \\prod_{k=1}^{K} \\big[ \\pi_{k}p(x|\\mu{k})\\big]^{z{k}} \\\\\r\n","& = \\prod_{k=1}^{K} \\big[ \\pi_{k}p(x | \\mu_{k}) \\big]^{z{k}} \\biggm\\lvert_{z_{1}=1} + ... + \\prod_{k=1}^{K} \\big[ \\pi_{k}p(x | \\mu_{k}) \\big]^{z{k}} \\biggm\\lvert_{z_{K}=1} \\\\\r\n","& = \\pi_{1} p(x | \\mu_{1}) + ... + \\pi_{K} p(x | \\mu_{K}) \\\\\r\n","& = \\sum_{k=1}^{K} \\pi_{k}p(x|\\mu_{k})\r\n","\\end{aligned}\r\n","\\end{equation}\r\n","\r\n","To elaborate the above proof, the summation over $z$ is made up of $K$ terms and the $k$-$th$ term corresponds to $z_{k} = 1$ and other $z_{j}$, where $ j \\neq k$, equals $0$. \r\n","\r\n","Therefore, the $k$-$th$ term will reduce to $\\pi_{k}p(x|\\mu_{k})$ which is equal to **(9.47)**.\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"0BTMIRsERQ9U"},"source":["## Discussion Exercises"]},{"cell_type":"markdown","metadata":{"id":"ZgiSYKVJ0LwZ"},"source":["**<font color=\"blue\">(Exercise D1)** The models we looked this week require knowing the number of clusters ahead of time.  What might you do if you don't know the number of clusters.  Investigation possible solutions.</font>\r\n","\r\n","<font color=\"green\"><u><b>Answer</b></u></font>\r\n","\r\n","The correct choice of **number of clusters** is often ambiguous, with interpretations depending on the shape and scale of the distribution of points in a data set and the desired clustering resolution of the user. There are several possible soultions for making this decision:[1]\r\n","\r\n","1. The elbow method\r\n","2. X-means clustering\r\n","3. Information criterion approach\r\n","4. An information–theoretic approach\r\n","5. The silhouette method\r\n","6. Cross-validation\r\n","7. Finding number of clusters in text databases\r\n","8. Analyzing the kernel matrix\r\n","\r\n","In this assignment, I'd like to put my focus on the **elbow method** since I learned about this method when I took the data science certificate program. (Basicly, I'm most familiar with this method).\r\n","\r\n","##### <u><b>Elbow method</b></u>\r\n","\r\n","The elbow method is a heuristic used in determining the number of clusters in a data set. The method consists of plotting the explained variation as a function of the number of clusters, and picking the elbow of the curve as the number of clusters to use.[2]\r\n","\r\n","The idea of the elbow method is to run k-means clustering on the dataset for a range of values of k (say, k from 1 to 10 in the examples above), and for each value of k calculate the sum of squared errors (SSE). Like this:\r\n","\r\n","\r\n","```\r\n","var sse = {};\r\n","for (var k = 1; k <= maxK; ++k) {\r\n","    sse[k] = 0;\r\n","    clusters = kmeans(dataset, k);\r\n","    clusters.forEach(function(cluster) {\r\n","        mean = clusterMean(cluster);\r\n","        cluster.forEach(function(datapoint) {\r\n","            sse[k] += Math.pow(datapoint - mean, 2);\r\n","        });\r\n","    });\r\n","}\r\n","```\r\n","\r\n","Then, plot a line chart of the SSE for each value of k. If the line chart looks like an arm, then the \"elbow\" on the arm is the value of k that is the best. \r\n","\r\n","Please look at the following picture to see how the elbow's plot will look like:\r\n","<image src=\"https://media.geeksforgeeks.org/wp-content/uploads/20190606105746/inertia.png\" />\r\n","\r\n","Why we pick the number **<i>k</i>**? (This is case, it's number **3** in the plot). In the simple word, we pick **3** becuase adding another cluster doesn’t give much better modeling of the data. If we look at the plot, we can see that increasing the number of clusters more than **3** won't decrease much of **sum of squared errors**.\r\n","\r\n","Note: this method has the similar concept with **distortion function** in the assignment 4.\r\n","\r\n","\r\n","[1] https://en.wikipedia.org/wiki/Determining_the_number_of_clusters_in_a_data_set\r\n","\r\n","[2] https://en.wikipedia.org/wiki/Elbow_method_(clustering)"]},{"cell_type":"markdown","metadata":{"id":"KlKdcQnnYSgq"},"source":["**(Exercise D2)** Describe the strengths and weaknesses of the K-means clustering.  Describe the strengths and weaknesses of the GMM model.  When would you choose a GMM over K-means?  When would you choose K-means over a GMM?"]},{"cell_type":"markdown","metadata":{"id":"7EPzbrSLv5Si"},"source":["**(Exercise D3)** Will K-means always converge?  Will it converge to the optimal solution?  What about the GMM?  Justify your answer."]},{"cell_type":"markdown","metadata":{"id":"Z0LWK2oJCA-f"},"source":["**(Exercise D4)** Is the Gaussian Mixture Model a member of the Exponential Family?  Why or why not?"]},{"cell_type":"markdown","metadata":{"id":"UA86yWCbOyMv"},"source":["## Programming Exercises\n","The assignments are based on the first part of assignment 4.  To do the programming exercises, you'll need to get an early start on the assignment."]},{"cell_type":"markdown","metadata":{"id":"ODlOCQvxzpZb"},"source":["**<font color=\"blue\">(Exercise P1)** In assignment 4, we look at the implementation of the k-means clustering algorithm.  Implement the distortion function from the reading material and plot the value over time for many runs for random starting clusters.  Does it always converge?  Does it always monotonicaly decrease?</font>    \r\n","\r\n","<font color=\"green\"><u><b>Answer</b></u></font>\r\n","\r\n","*   **Does it always converge?**\r\n","\r\n","    <font color=\"green\"><b>Answer:</b></font> The algorithm always converges (by-definition) but not necessarily to global optimum.\r\n","\r\n","*   **Does it always monotonicaly decrease?**\r\n","\r\n","    <font color=\"green\"><b>Answer:</b></font>\r\n"," \r\n","    the **distort funtion** always monotonicaly decrease.\r\n","\r\n","Below is my implementation.\r\n"]},{"cell_type":"code","metadata":{"id":"xYKv-dFOCMCz","colab":{"base_uri":"https://localhost:8080/","height":516},"executionInfo":{"status":"ok","timestamp":1614559190797,"user_tz":420,"elapsed":574,"user":{"displayName":"Salinee Kingbaisomboon","photoUrl":"","userId":"02359635892756858441"}},"outputId":"f509065a-6f5d-45f1-b629-dca8cbcc5067"},"source":["################################################\n","####### Place your implementation here #########\n","################################################\n","\n","from sklearn import cluster, datasets\n","import numpy as np\n","import torch\n","import matplotlib.pyplot as plt\n","\n","torch.manual_seed(42)\n","\n","X, y = datasets.make_blobs(n_samples=100, random_state=10)\n","X = torch.tensor(X).float()\n","\n","cluster_means = torch.randn(3,2)\n","\n","# Array to hold the distortion numbers for each iteration\n","distortions = []\n","\n","for step in range(10):\n","  pairwise_distance = torch.cdist(X, cluster_means, compute_mode='use_mm_for_euclid_dist_if_necessary')\n","  cluster_indicator = torch.min(pairwise_distance, 1).indices\n","\n","  cluster_means = [X[cluster_indicator == i].mean(0) for i in range(len(cluster_indicator))]\n","  cluster_means = torch.stack(cluster_means)\n","  cluster_means = cluster_means[~torch.any(cluster_means.isnan(),dim=1)]\n","\n","  square_error_list = []\n","  for i in range(len(cluster_indicator)):\n","    cluster_np = X[cluster_indicator == i].numpy()\n","    if cluster_np.size > 0:\n","      mean = cluster_np.mean(0)\n","      square_error = np.linalg.norm(cluster_np - mean)**2 # squared of distance between the each point and it's centroid\n","      square_error_list.append(square_error) # append to list of squared errors for this cluster\n","  sum_square_error = np.sum(square_error_list) # sum all squared errors for this cluster (return scalar)\n","  distortions.append(sum_square_error) # append the sse number to the list of distortions for each iterations (Total number is 10)\n","\n","print('\\033[34m' + '\\033[1m' + 'Distortions Size' + '\\033[0m')\n","print(len(distortions))\n","print('\\033[34m' + '\\033[1m' + 'Distortions Numpy Array' + '\\033[0m')\n","print('\\n'.join(str(x) for x in distortions))\n","\n","# plot\n","plt.plot(range(1, len(distortions)+1), distortions, color='b', marker='o')\n","plt.xlabel('Number of Steps')\n","plt.ylabel('Sum of Distortions')\n","plt.title('Distortion over time (steps)')\n","plt.show()"],"execution_count":13,"outputs":[{"output_type":"stream","text":["\u001b[34m\u001b[1mDistortions Size\u001b[0m\n","10\n","\u001b[34m\u001b[1mDistortions Numpy Array\u001b[0m\n","668.2369210599848\n","186.36588819536087\n","186.36588819536087\n","186.36588819536087\n","186.36588819536087\n","186.36588819536087\n","186.36588819536087\n","186.36588819536087\n","186.36588819536087\n","186.36588819536087\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"cMjh0-0XOZFW"},"source":["**(Exercise P2)** In assignment 4, we look at the implementation of the k-means clustering algorithm.  Try running the algorithm many times with random starting clusters and plot a histogram of the distortion function values.  Do you see evidence that it sometimes doesn't converge to the optimum value?"]},{"cell_type":"code","metadata":{"id":"Hxm4etgMOsXH"},"source":["################################################\n","####### Place your implementation here #########\n","################################################"],"execution_count":null,"outputs":[]}]}